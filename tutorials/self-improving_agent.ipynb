{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-assets/phoenix/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">Evaluating an Agent</h1>\n",
    "\n",
    "This notebook serves as an end-to-end example of how to trace and evaluate an agent. The example uses a \"talk-to-your-data\" agent as its example.\n",
    "\n",
    "The notebook includes:\n",
    "* Manually instrumenting an agent using Phoenix decorators\n",
    "* Evaluating function calling accuracy using LLM as a Judge\n",
    "* Evaluating function calling accuracy by comparing to ground truth\n",
    "* Evaluating SQL query generation\n",
    "* Evaluating Python code generation\n",
    "* Evaluating the path of an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in /home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages (0.6.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install uv\n",
    "!uv pip install -q openai python-dotenv \"arize-phoenix>=8.8.0\" \"arize-phoenix-otel>=0.8.0\" openinference-instrumentation-openai python-dotenv duckdb \"openinference-instrumentation>=0.1.21\" tqdm dspy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies, Import Libraries, Set API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import json\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from opentelemetry.trace import StatusCode\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm import tqdm\n",
    "\n",
    "from phoenix.client import Client as PhoenixClient\n",
    "from phoenix.otel import register\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "client = OpenAI()\n",
    "model = \"gpt-4o-mini\"\n",
    "project_name = \"self-improving-agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Phoenix Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign up for a free instance of [Phoenix Cloud](https://app.phoenix.arize.com) to get your API key. If you'd prefer, you can instead [self-host Phoenix](https://docs.arize.com/phoenix/deployment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"PHOENIX_API_KEY\") is None:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass(\"Enter your Phoenix API key: \")\n",
    "\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"https://app.phoenix.arize.com/\"\n",
    "os.environ[\"PHOENIX_CLIENT_HEADERS\"] = f\"api_key={os.getenv('PHOENIX_API_KEY')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DependencyConflict: requested: \"openai >= 1.69.0\" but found: \"openai 1.61.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: self-improving-agent\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: https://app.phoenix.arize.com/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {'api_key': '****', 'authorization': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracer_provider = register(\n",
    "    project_name=project_name,\n",
    "    auto_instrument=True,\n",
    ")\n",
    "\n",
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "Your agent will interact with a local database. Start by loading in that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_Number</th>\n",
       "      <th>SKU_Coded</th>\n",
       "      <th>Product_Class_Code</th>\n",
       "      <th>Sold_Date</th>\n",
       "      <th>Qty_Sold</th>\n",
       "      <th>Total_Sale_Value</th>\n",
       "      <th>On_Promo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1320</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>3</td>\n",
       "      <td>56.849998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2310</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3080</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2310</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>1</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4840</td>\n",
       "      <td>6172800</td>\n",
       "      <td>22875</td>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>1</td>\n",
       "      <td>18.950001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store_Number  SKU_Coded  Product_Class_Code   Sold_Date  Qty_Sold  \\\n",
       "0          1320    6172800               22875  2021-11-02         3   \n",
       "1          2310    6172800               22875  2021-11-03         1   \n",
       "2          3080    6172800               22875  2021-11-03         1   \n",
       "3          2310    6172800               22875  2021-11-06         1   \n",
       "4          4840    6172800               22875  2021-11-07         1   \n",
       "\n",
       "   Total_Sale_Value  On_Promo  \n",
       "0         56.849998         0  \n",
       "1         18.950001         0  \n",
       "2         18.950001         0  \n",
       "3         18.950001         0  \n",
       "4         18.950001         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_sales_df = pd.read_parquet(\n",
    "    \"https://storage.googleapis.com/arize-phoenix-assets/datasets/unstructured/llm/llama-index/Store_Sales_Price_Elasticity_Promotions_Data.parquet\"\n",
    ")\n",
    "store_sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the tools\n",
    "\n",
    "Now you can define your agent tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 1: Database Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The available columns are: {columns}\n",
    "The table name is: {table_name}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(\n",
    "        prompt=prompt, columns=columns, table_name=table_name\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "@tracer.tool    ()\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of sales data lookup from parquet file using SQL\"\"\"\n",
    "    try:\n",
    "        table_name = \"sales\"\n",
    "        # Read the parquet file into a DuckDB table\n",
    "        duckdb.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM store_sales_df\")\n",
    "\n",
    "        print(store_sales_df.columns)\n",
    "        print(table_name)\n",
    "        sql_query = generate_sql_query(prompt, store_sales_df.columns, table_name)\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        with tracer.start_as_current_span(\n",
    "            \"execute_sql_query\", openinference_span_kind=\"chain\"\n",
    "        ) as span:\n",
    "            span.set_input(value=sql_query)\n",
    "\n",
    "            # Execute the SQL query\n",
    "            result = duckdb.sql(sql_query).df()\n",
    "            span.set_output(value=str(result))\n",
    "            span.set_status(StatusCode.OK)\n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_data = lookup_sales_data(\"Show me all the sales for store 1320 on November 1st, 2021\")\n",
    "# example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 2: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")\n",
    "\n",
    "\n",
    "@tracer.chain()\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\n",
    "\n",
    "    Args:\n",
    "        data: String containing the data to visualize\n",
    "        visualization_goal: Description of what the visualization should show\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing line chart configuration\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Generate a chart configuration based on this data: {data}\n",
    "    The goal is to show: {visualization_goal}\"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Extract axis and title info from response\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        # Return structured chart config\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data,\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\",\n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data,\n",
    "        }\n",
    "\n",
    "\n",
    "@tracer.chain()\n",
    "def create_chart(config: VisualizationConfig) -> str:\n",
    "    \"\"\"Create a chart based on the configuration\"\"\"\n",
    "    prompt = f\"\"\"Write python code to create a chart based on the following configuration.\n",
    "    Only return the code, no other text.\n",
    "    config: {config}\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    code = code.strip()\n",
    "\n",
    "    return code\n",
    "\n",
    "\n",
    "@tracer.tool()\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    \"\"\"Generate a visualization based on the data and goal\"\"\"\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code = generate_visualization(example_data, \"A line chart of sales over each day in november.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool()\n",
    "def run_python_code(code: str) -> str:\n",
    "    \"\"\"Execute Python code in a restricted environment\"\"\"\n",
    "    # Create restricted globals/locals dictionaries with plotting libraries\n",
    "    restricted_globals = {\n",
    "        \"__builtins__\": {\n",
    "            \"print\": print,\n",
    "            \"len\": len,\n",
    "            \"range\": range,\n",
    "            \"sum\": sum,\n",
    "            \"min\": min,\n",
    "            \"max\": max,\n",
    "            \"int\": int,\n",
    "            \"float\": float,\n",
    "            \"str\": str,\n",
    "            \"list\": list,\n",
    "            \"dict\": dict,\n",
    "            \"tuple\": tuple,\n",
    "            \"set\": set,\n",
    "            \"round\": round,\n",
    "            \"__import__\": __import__,\n",
    "            \"json\": __import__(\"json\"),\n",
    "        },\n",
    "        \"plt\": __import__(\"matplotlib.pyplot\"),\n",
    "        \"pd\": __import__(\"pandas\"),\n",
    "        \"np\": __import__(\"numpy\"),\n",
    "        \"sns\": __import__(\"seaborn\"),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Execute code in restricted environment\n",
    "        exec_locals = {}\n",
    "        exec(code, restricted_globals, exec_locals)\n",
    "\n",
    "        # Capture any printed output or return the plot\n",
    "        exec_locals.get(\"__builtins__\", {}).get(\"_\", \"\")\n",
    "        if \"plt\" in exec_locals:\n",
    "            return exec_locals[\"plt\"]\n",
    "\n",
    "        # Try to parse output as JSON before returning\n",
    "        return \"Code executed successfully\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool 3: Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.tool()\n",
    "def analyze_sales_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered sales data analysis\"\"\"\n",
    "    # Construct prompt based on analysis type and data subset\n",
    "    prompt = f\"\"\"Analyze the following data: {data}\n",
    "    Your job is to answer the following question: {prompt}\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "\n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis = analyze_sales_data(\"What is the most popular product SKU?\", example_data)\n",
    "# analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Schema:\n",
    "\n",
    "You'll need to pass your tool descriptions into your agent router. The following code allows you to easily do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The unchanged prompt that the user provided.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"prompt\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_sales_data\",\n",
    "            \"description\": \"Analyze sales data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The lookup_sales_data tool's output.\",\n",
    "                    },\n",
    "                    \"prompt\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The unchanged prompt that the user provided.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The lookup_sales_data tool's output.\",\n",
    "                    },\n",
    "                    \"visualization_goal\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The goal of the visualization.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    # {\n",
    "    #     \"type\": \"function\",\n",
    "    #     \"function\": {\n",
    "    #         \"name\": \"run_python_code\",\n",
    "    #         \"description\": \"Run Python code in a restricted environment\",\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"code\": {\"type\": \"string\", \"description\": \"The Python code to run.\"}\n",
    "    #             },\n",
    "    #             \"required\": [\"code\"]\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data,\n",
    "    \"analyze_sales_data\": analyze_sales_data,\n",
    "    \"generate_visualization\": generate_visualization,\n",
    "    # \"run_python_code\": run_python_code\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Router Prompt in Phoenix\n",
    "\n",
    "Saving prompts in Phoenix allows for easy version tracking of your prompts. For this example, since you'll be optimizing the router prompt, we'll save that as a Prompt in Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohappyeyeballs==2.6.1\n",
      "aiohttp==3.11.16\n",
      "aioitertools==0.12.0\n",
      "aiosignal==1.3.2\n",
      "aiosqlite==0.21.0\n",
      "alembic==1.15.2\n",
      "annotated-types==0.7.0\n",
      "anyio==4.9.0\n",
      "arize-phoenix==8.26.2\n",
      "arize-phoenix-client==1.3.0\n",
      "arize-phoenix-evals==0.20.5\n",
      "arize-phoenix-otel==0.9.2\n",
      "asttokens==3.0.0\n",
      "asyncer==0.0.8\n",
      "attrs==25.3.0\n",
      "Authlib==1.5.2\n",
      "backoff==2.2.1\n",
      "cachetools==5.5.2\n",
      "certifi==2025.1.31\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.4.1\n",
      "click==8.1.8\n",
      "cloudpickle==3.1.1\n",
      "colorlog==6.9.0\n",
      "comm==0.2.2\n",
      "cryptography==44.0.2\n",
      "datasets==3.5.0\n",
      "debugpy==1.8.14\n",
      "decorator==5.2.1\n",
      "Deprecated==1.2.18\n",
      "dill==0.3.8\n",
      "diskcache==5.6.3\n",
      "distro==1.9.0\n",
      "dnspython==2.7.0\n",
      "dspy==2.6.17\n",
      "duckdb==1.2.2\n",
      "email_validator==2.2.0\n",
      "executing==2.2.0\n",
      "fastapi==0.115.12\n",
      "filelock==3.18.0\n",
      "frozenlist==1.5.0\n",
      "fsspec==2024.12.0\n",
      "googleapis-common-protos==1.70.0\n",
      "graphql-core==3.2.6\n",
      "greenlet==3.2.0\n",
      "grpc-interceptor==0.15.4\n",
      "grpcio==1.71.0\n",
      "h11==0.14.0\n",
      "httpcore==1.0.8\n",
      "httpx==0.28.1\n",
      "huggingface-hub==0.30.2\n",
      "idna==3.10\n",
      "importlib_metadata==8.6.1\n",
      "ipykernel==6.29.5\n",
      "ipython==9.1.0\n",
      "ipython_pygments_lexers==1.1.1\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.6\n",
      "jiter==0.9.0\n",
      "joblib==1.4.2\n",
      "json_repair==0.41.1\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2024.10.1\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "litellm==1.63.7\n",
      "magicattr==0.1.6\n",
      "Mako==1.3.10\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "multidict==6.4.3\n",
      "multiprocess==0.70.16\n",
      "nest-asyncio==1.6.0\n",
      "numpy==2.2.4\n",
      "openai==1.61.0\n",
      "openinference-instrumentation==0.1.27\n",
      "openinference-instrumentation-openai==0.1.25\n",
      "openinference-semantic-conventions==0.1.17\n",
      "opentelemetry-api==1.32.1\n",
      "opentelemetry-exporter-otlp==1.32.1\n",
      "opentelemetry-exporter-otlp-proto-common==1.32.1\n",
      "opentelemetry-exporter-otlp-proto-grpc==1.32.1\n",
      "opentelemetry-exporter-otlp-proto-http==1.32.1\n",
      "opentelemetry-instrumentation==0.53b1\n",
      "opentelemetry-proto==1.32.1\n",
      "opentelemetry-sdk==1.32.1\n",
      "opentelemetry-semantic-conventions==0.53b1\n",
      "optuna==4.3.0\n",
      "packaging==24.2\n",
      "pandas==2.2.3\n",
      "parso==0.8.4\n",
      "pexpect==4.9.0\n",
      "platformdirs==4.3.7\n",
      "prompt_toolkit==3.0.51\n",
      "propcache==0.3.1\n",
      "protobuf==5.29.4\n",
      "psutil==7.0.0\n",
      "ptyprocess==0.7.0\n",
      "pure_eval==0.2.3\n",
      "pyarrow==19.0.1\n",
      "pycparser==2.22\n",
      "pydantic==2.11.3\n",
      "pydantic_core==2.33.1\n",
      "Pygments==2.19.1\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.1.0\n",
      "python-multipart==0.0.20\n",
      "pytz==2025.2\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.4.0\n",
      "referencing==0.36.2\n",
      "regex==2024.11.6\n",
      "requests==2.32.3\n",
      "rich==14.0.0\n",
      "rpds-py==0.24.0\n",
      "scikit-learn==1.6.1\n",
      "scipy==1.15.2\n",
      "six==1.17.0\n",
      "sniffio==1.3.1\n",
      "SQLAlchemy==2.0.40\n",
      "sqlean.py==3.47.0\n",
      "stack-data==0.6.3\n",
      "starlette==0.46.2\n",
      "strawberry-graphql==0.265.1\n",
      "tenacity==9.1.2\n",
      "threadpoolctl==3.6.0\n",
      "tiktoken==0.9.0\n",
      "tokenizers==0.21.1\n",
      "tornado==6.4.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "typing-inspection==0.4.0\n",
      "typing_extensions==4.13.2\n",
      "tzdata==2025.2\n",
      "ujson==5.10.0\n",
      "urllib3==2.4.0\n",
      "uv==0.6.14\n",
      "uvicorn==0.34.1\n",
      "wcwidth==0.2.13\n",
      "websockets==15.0.1\n",
      "wrapt==1.17.2\n",
      "xxhash==3.5.0\n",
      "yarl==1.20.0\n",
      "zipp==3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (8.24.0) and client (8.26.2) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from openai.types.chat.completion_create_params import CompletionCreateParamsBase\n",
    "\n",
    "import phoenix as px\n",
    "from phoenix.client.types import PromptVersion\n",
    "\n",
    "params = CompletionCreateParamsBase(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=tools,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"{user_query}\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt_name = \"self-improving-agent-router\"\n",
    "prompt = px.Client().prompts.create(\n",
    "    name=prompt_name,\n",
    "    version=PromptVersion.from_openai(params),\n",
    ")\n",
    "\n",
    "px.Client().prompts.tags.create(\n",
    "    prompt_version_id=prompt.id, name=\"production\", description=\"Ready for production environment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Hello'}\n"
     ]
    }
   ],
   "source": [
    "phoenix_production_router_prompt = PhoenixClient().prompts.get(\n",
    "    prompt_identifier=\"self-improving-agent-router\", tag=\"production\"\n",
    ")\n",
    "vars = {\"user_query\":\"Hello\"}\n",
    "\n",
    "messages = phoenix_production_router_prompt._template[\"messages\"]\n",
    "\n",
    "system_message = messages[0]\n",
    "\n",
    "user_message = messages[1]\n",
    "user_message[\"content\"] = user_message[\"content\"].format(**vars)\n",
    "print(user_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent logic\n",
    "\n",
    "With the tools defined, you're ready to define the main routing and tool call handling steps of your agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    for tool_call in tool_calls:\n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "\n",
    "        messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_call.id})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_main_span(variables: dict):\n",
    "    print(\"Starting main span with messages:\", variables)\n",
    "\n",
    "    phoenix_production_router_prompt = PhoenixClient().prompts.get(\n",
    "        prompt_identifier=\"self-improving-agent-router\", tag=\"production\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    messages = phoenix_production_router_prompt._template[\"messages\"]\n",
    "    composed_messages = []\n",
    "\n",
    "    for message in messages:\n",
    "        try:\n",
    "            if \"content\" in message:\n",
    "                message[\"content\"] = message[\"content\"].format(**variables)\n",
    "            composed_messages.append(message)\n",
    "        except KeyError:\n",
    "            # If formatting fails, append message unchanged\n",
    "            composed_messages.append(message)\n",
    "\n",
    "    with tracer.start_as_current_span(\"AgentRun\", openinference_span_kind=\"agent\") as span:\n",
    "        span.set_input(value=composed_messages)\n",
    "        ret = run_agent(composed_messages)\n",
    "        print(\"Main span completed with return value:\", ret)\n",
    "        span.set_output(value=ret)\n",
    "        span.set_status(StatusCode.OK)\n",
    "        return ret\n",
    "\n",
    "\n",
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    # if isinstance(messages, str):\n",
    "    #     messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "    #     print(\"Converted string message to list format\")\n",
    "\n",
    "    # # Check and add system prompt if needed\n",
    "    # if not any(\n",
    "    #     isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "    # ):\n",
    "    #     phoenix_production_router_prompt = PhoenixClient().prompts.get(\n",
    "    #         prompt_identifier=\"self-improving-agent-router\", tag=\"production\"\n",
    "    #     )\n",
    "\n",
    "        \n",
    "\n",
    "    #     system_prompt = {\n",
    "    #         \"role\": \"system\",\n",
    "    #         \"content\": phoenix_production_router_prompt,\n",
    "    #     }\n",
    "    #     messages.append(system_prompt)\n",
    "    #     print(\"Added system prompt to messages\")\n",
    "\n",
    "    while True:\n",
    "        # Router call span\n",
    "        print(\"Starting router call span\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"router_call\",\n",
    "            openinference_span_kind=\"chain\",\n",
    "        ) as span:\n",
    "            span.set_input(value=messages)\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "            )\n",
    "\n",
    "            messages.append(response.choices[0].message.model_dump())\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "            span.set_status(StatusCode.OK)\n",
    "\n",
    "            if tool_calls:\n",
    "                # Tool calls span\n",
    "                print(\"Processing tool calls\")\n",
    "                messages = handle_tool_calls(tool_calls, messages)\n",
    "                span.set_output(value=tool_calls)\n",
    "            else:\n",
    "                print(\"No tool calls, returning final response\")\n",
    "                span.set_output(value=response.choices[0].message.content)\n",
    "\n",
    "                return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the agent\n",
    "\n",
    "Your agent is now good to go! Let's try it out with some example questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: {'user_query': 'Create a line chart showing sales in 2021'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'Create a line chart showing sales in 2021'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: I have created a line chart showing the total quantity sold and total sale value for the months of November and December in 2021. \n",
      "\n",
      "If you would like any adjustments or further analysis, please let me know!\n",
      "I have created a line chart showing the total quantity sold and total sale value for the months of November and December in 2021. \n",
      "\n",
      "If you would like any adjustments or further analysis, please let me know!\n"
     ]
    }
   ],
   "source": [
    "ret = start_main_span({\"user_query\":\"Create a line chart showing sales in 2021\"})\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: {'user_query': 'What was the most popular product SKU?'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'What was the most popular product SKU?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: The most popular product SKU is 6200700, with a total quantity sold of 52,262 units.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  10%|‚ñà         | 1/10 [00:04<00:36,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: {'user_query': 'What was the total revenue across all stores?'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'What was the total revenue across all stores?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: The total revenue across all stores was approximately $13,272,640.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  20%|‚ñà‚ñà        | 2/10 [00:07<00:30,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: {'user_query': 'Which store had the highest sales volume?'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'Which store had the highest sales volume?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: The store with the highest sales volume is Store Number 2970, with total sales amounting to approximately $836,341.33.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:11<00:27,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: {'user_query': 'Create a bar chart showing total sales by store'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'Create a bar chart showing total sales by store'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: Here is the bar chart showing total sales by store:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "data = {\n",
      "    'Store_Number': [880, 3410, 2750, 1980, 1210, 330, 1760, 3630, 2310, 2200,\n",
      "                     1870, 990, 3300, 4070, 3080, 2090, 2640, 4840, 3740, 770,\n",
      "                     3520, 660, 2860, 2420, 4730, 1320, 1540, 2970, 2530, 4400,\n",
      "                     1100, 3190, 1650, 4180, 550],\n",
      "    'Total_Sales': [420302.088397, 410567.848126, 453664.808068, 242290.828499,\n",
      "                    508393.767785, 370503.687331, 350747.617798, 405034.547846,\n",
      "                    412579.388504, 361173.288199, 401070.997685, 378433.018639,\n",
      "                    619660.167018, 322307.968330, 495458.238811, 309996.247965,\n",
      "                    308990.318559, 389056.668316, 359729.808228, 292968.918642,\n",
      "                    145701.079372, 343594.978075, 132320.519487, 406715.767402,\n",
      "                    239711.708869, 592832.067579, 427777.427815, 836341.327191,\n",
      "                    324046.518720, 95745.620250, 497509.528013, 335035.018792,\n",
      "                    580443.007953, 272208.118542, 229727.498752]\n",
      "}\n",
      "\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.bar(df['Store_Number'], df['Total_Sales'], color='blue')\n",
      "plt.title('Total Sales by Store')\n",
      "plt.xlabel('Store Number')\n",
      "plt.ylabel('Total Sales')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(axis='y')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "This script will create a bar chart that displays the total sales for each store. You can run this code in your local Python environment to view the chart.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:39<01:20, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: {'user_query': 'What percentage of items were sold on promotion?'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'What percentage of items were sold on promotion?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: Approximately 62.56% of items were sold on promotion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:45<00:52, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: {'user_query': 'Plot daily sales volume over time'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'Plot daily sales volume over time'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [03:55<04:47, 71.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main span completed with return value: The daily sales volume over time has been plotted successfully. Please take a look at the graph to analyze the trends in sales volume. If you have any further requests or need additional insights, feel free to ask!\n",
      "Starting main span with messages: {'user_query': 'What was the average transaction value?'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'What was the average transaction value?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: The average transaction value was approximately $19.02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [03:59<02:28, 49.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: {'user_query': 'Create a box plot of transaction values'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'Create a box plot of transaction values'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The write operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 114, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The write operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 114, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/trace/__init__.py\", line 587, in use_span\n",
      "    yield span\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openinference/instrumentation/_tracers.py\", line 140, in start_as_current_span\n",
      "    yield cast(OpenInferenceSpan, current_span)\n",
      "  File \"/tmp/ipykernel_7326/475595586.py\", line 62, in run_agent\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1049, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1098, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1049, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1098, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1064, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-Q2FGcHGoGKfes9heonRVzF1K on tokens per min (TPM): Limit 4000000, Requested 4361887. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The write operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 114, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "Processing questions:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [06:02<02:25, 72.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: Create a box plot of transaction values\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-Q2FGcHGoGKfes9heonRVzF1K on tokens per min (TPM): Limit 4000000, Requested 4361887. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Starting main span with messages: {'user_query': 'Which products were frequently purchased together?'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'Which products were frequently purchased together?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The write operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 114, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The write operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 114, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting router call span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/trace/__init__.py\", line 587, in use_span\n",
      "    yield span\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openinference/instrumentation/_tracers.py\", line 140, in start_as_current_span\n",
      "    yield cast(OpenInferenceSpan, current_span)\n",
      "  File \"/tmp/ipykernel_7326/475595586.py\", line 62, in run_agent\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1064, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'messages[3].content': string too long. Expected a string with maximum length 10485760, but got a string with length 13390424 instead.\", 'type': 'invalid_request_error', 'param': 'messages[3].content', 'code': 'string_above_max_length'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The write operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/util/util.py\", line 38, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
      "    conn.request(\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/urllib3/connection.py\", line 459, in request\n",
      "    self.send(chunk)\n",
      "  File \"/usr/lib/python3.12/http/client.py\", line 1055, in send\n",
      "    self.sock.sendall(data)\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1210, in sendall\n",
      "    v = self.send(byte_view[count:])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/ssl.py\", line 1179, in send\n",
      "    return self._sslobj.write(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 114, in on_end\n",
      "    self.span_exporter.export((span,))\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/requests/adapters.py\", line 682, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', TimeoutError('The write operation timed out'))\n",
      "Processing questions:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [06:56<01:06, 66.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: Which products were frequently purchased together?\n",
      "Error code: 400 - {'error': {'message': \"Invalid 'messages[3].content': string too long. Expected a string with maximum length 10485760, but got a string with length 13390424 instead.\", 'type': 'invalid_request_error', 'param': 'messages[3].content', 'code': 'string_above_max_length'}}\n",
      "Starting main span with messages: {'user_query': 'Plot a line graph showing the sales trend over time with a 7-day moving average'}\n",
      "Running agent with messages: [{'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'user', 'content': 'Plot a line graph showing the sales trend over time with a 7-day moving average'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n",
      "Index(['Store_Number', 'SKU_Coded', 'Product_Class_Code', 'Sold_Date',\n",
      "       'Qty_Sold', 'Total_Sale_Value', 'On_Promo'],\n",
      "      dtype='object')\n",
      "sales\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Processing tool calls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [11:43<00:00, 70.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question: Plot a line graph showing the sales trend over time with a 7-day moving average\n",
      "Unterminated string starting at: line 1 column 9 (char 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: this will take ~15 minutes to run\n",
    "\n",
    "agent_questions = [\n",
    "    \"What was the most popular product SKU?\",\n",
    "    \"What was the total revenue across all stores?\",\n",
    "    \"Which store had the highest sales volume?\",\n",
    "    \"Create a bar chart showing total sales by store\",\n",
    "    \"What percentage of items were sold on promotion?\",\n",
    "    \"Plot daily sales volume over time\",\n",
    "    \"What was the average transaction value?\",\n",
    "    \"Create a box plot of transaction values\",\n",
    "    \"Which products were frequently purchased together?\",\n",
    "    \"Plot a line graph showing the sales trend over time with a 7-day moving average\",\n",
    "]\n",
    "\n",
    "for question in tqdm(agent_questions, desc=\"Processing questions\"):\n",
    "    try:\n",
    "        ret = start_main_span({\"user_query\":question})\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {question}\")\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Agent Traces](https://storage.googleapis.com/arize-phoenix-assets/assets/images/agent-traces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Agent in Development\n",
    "\n",
    "Before deploying your agent, you can first test it on a series of test cases. You'll need to initially either generate or source these test cases yourself, but in future rounds, this will be automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to uninstrument while already uninstrumented\n"
     ]
    }
   ],
   "source": [
    "OpenAIInstrumentor().uninstrument()  # Uninstrument the OpenAI client to avoid capturing LLM as a Judge evaluation calls in your same project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "import phoenix as px\n",
    "from phoenix.evals import TOOL_CALLING_PROMPT_TEMPLATE, OpenAIModel, llm_classify\n",
    "from phoenix.experiments import run_experiment\n",
    "from phoenix.experiments.types import Example\n",
    "from phoenix.trace import SpanEvaluations\n",
    "from phoenix.trace.dsl import SpanQuery\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (8.24.0) and client (8.26.2) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "px_client = px.Client()\n",
    "eval_model = OpenAIModel(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling Evals using Ground Truth\n",
    "\n",
    "In order to run a test on the ground truth data effectively, you can use an Experiment.\n",
    "\n",
    "Experiments follow a standard step-by-step process in Phoenix:\n",
    "1. Create a dataset of test cases, and optionally, expected outputs\n",
    "2. Create a task to run on each test case - usually this is invoking your agent or a specifc step of it\n",
    "3. Create evaluator(s) to run on each output of your task\n",
    "4. Visualize results in Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading dataset...\n",
      "üíæ Examples uploaded: https://app.phoenix.arize.com/datasets/RGF0YXNldDoz/examples\n",
      "üóÑÔ∏è Dataset version ID: RGF0YXNldFZlcnNpb246NA==\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "id = str(uuid.uuid4())\n",
    "\n",
    "# Create a list of tuples with input_messages and next_tool_call\n",
    "data = [\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Plot daily sales volume over time\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"call_1\",\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": \"lookup_sales_data\",\n",
    "                            \"arguments\": '{\"prompt\":\"Plot daily sales volume over time\"}',\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": \"call_1\",\n",
    "                \"content\": \"     Sold_Date  Daily_Sales_Volume\\n0   2021-11-01              1021.0\\n1   2021-11-02              1035.0\\n2   2021-11-03               900.0\",\n",
    "            },\n",
    "        ],\n",
    "        \"analyze_sales_data\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"What were the top selling products last month?\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "        ],\n",
    "        \"lookup_sales_data\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Show me the relationship between promotions and sales\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"call_2\",\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": \"lookup_sales_data\",\n",
    "                            \"arguments\": '{\"prompt\":\"Get promotion and sales data\"}',\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": \"call_2\",\n",
    "                \"content\": \"   On_Promo  Total_Sale_Value\\n0         0          1245678.50\\n1         1           987654.32\",\n",
    "            },\n",
    "        ],\n",
    "        \"analyze_sales_data\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Calculate the price elasticity for SKU 6172800\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "        ],\n",
    "        \"lookup_sales_data\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Create a bar chart of sales by store\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"call_3\",\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": \"lookup_sales_data\",\n",
    "                            \"arguments\": '{\"prompt\":\"Get sales by store\"}',\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": \"call_3\",\n",
    "                \"content\": \"   Store_Number  Total_Sales\\n0          1320      56849.99\\n1          2310      37900.00\\n2          3080      18950.00\",\n",
    "            },\n",
    "        ],\n",
    "        \"generate_visualization\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Find trends in seasonal sales patterns\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "        ],\n",
    "        \"lookup_sales_data\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"How does product class code affect sales volume?\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"call_4\",\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": \"lookup_sales_data\",\n",
    "                            \"arguments\": '{\"prompt\":\"Get sales volume by product class code\"}',\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": \"call_4\",\n",
    "                \"content\": \"   Product_Class_Code  Total_Qty_Sold\\n0               22875             7\\n1               34567            12\\n2               45678            23\",\n",
    "            },\n",
    "        ],\n",
    "        \"analyze_sales_data\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Generate a scatter plot of price vs quantity sold\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "        ],\n",
    "        \"lookup_sales_data\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Which stores have the highest promotion effectiveness?\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"call_5\",\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": \"lookup_sales_data\",\n",
    "                            \"arguments\": '{\"prompt\":\"Get promotion and sales data by store\"}',\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": \"call_5\",\n",
    "                \"content\": \"   Store_Number  Promo_Sales  Regular_Sales  Effectiveness\\n0          1320      12500.0        10000.0           1.25\\n1          2310      15000.0        10000.0           1.50\\n2          3080       9000.0        10000.0           0.90\",\n",
    "            },\n",
    "        ],\n",
    "        \"no tool called\",\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": \"Compare sales performance between 2020 and 2021\"},\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\",\n",
    "            },\n",
    "        ],\n",
    "        \"lookup_sales_data\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "dataframe = pd.DataFrame(data, columns=[\"input_messages\", \"next_tool_call\"])\n",
    "\n",
    "dataset = px_client.upload_dataset(\n",
    "    dataframe=dataframe,\n",
    "    dataset_name=f\"tool_calling_ground_truth_{id}\",\n",
    "    input_keys=[\"input_messages\"],\n",
    "    output_keys=[\"next_tool_call\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your task, you can simply run just the router call of your agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_router_step(example: Example) -> str:\n",
    "    input_messages = example.input.get(\"input_messages\")\n",
    "\n",
    "    phoenix_production_router_prompt = PhoenixClient().prompts.get(\n",
    "        prompt_identifier=\"self-improving-agent-router\", tag=\"production\"\n",
    "    )\n",
    "\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": phoenix_production_router_prompt,\n",
    "    }\n",
    "\n",
    "    # Replace the system message in input_messages with our production router prompt\n",
    "    # or add it if no system message exists\n",
    "    system_message_index = None\n",
    "\n",
    "    for i, message in enumerate(input_messages):\n",
    "        if message.get(\"role\") == \"system\":\n",
    "            system_message_index = i\n",
    "            break\n",
    "\n",
    "    if system_message_index is not None:\n",
    "        # Replace existing system message\n",
    "        input_messages[system_message_index] = system_prompt\n",
    "    else:\n",
    "        # Add system message if none exists\n",
    "        input_messages.insert(0, system_prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=input_messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    if response.choices[0].message.tool_calls is None:\n",
    "        return \"no tool called\"\n",
    "\n",
    "    tool_calls = []\n",
    "    for tool_call in response.choices[0].message.tool_calls:\n",
    "        tool_calls.append(tool_call.function.name)\n",
    "    return tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your evaluator can also be simple, since you have expected outputs. If you didn't have those expected outputs, you could instead use an LLM as a Judge here, or even basic code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tools_match(expected: str, output: str) -> bool:\n",
    "    if not isinstance(output, list):\n",
    "        return False\n",
    "\n",
    "    # Check if all expected tools are in output and no additional tools are present\n",
    "    expected_tools = expected.get(\"next_tool_call\").split(\", \")\n",
    "    expected_set = set(expected_tools)\n",
    "    output_set = set(output)\n",
    "\n",
    "    # Return True if the sets are identical (same elements, no extras)\n",
    "    return expected_set == output_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (8.24.0) and client (8.26.2) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Experiment started.\n",
      "üì∫ View dataset experiments: https://app.phoenix.arize.com/datasets/RGF0YXNldDoz/experiments\n",
      "üîó View this experiment: https://app.phoenix.arize.com/datasets/RGF0YXNldDoz/compare?experimentId=RXhwZXJpbWVudDox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |          | 0/10 (0.0%) | ‚è≥ 00:00<? | ?it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTQ3', repetition 1\n",
      "\u001b[0m\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTQ4', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |‚ñà‚ñà        | 2/10 (20.0%) | ‚è≥ 00:02<00:16 |  2.06s/it "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTQ5', repetition 1\n",
      "\u001b[0m\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTUw', repetition 1\n",
      "\u001b[0m\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTUx', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 (50.0%) | ‚è≥ 00:03<00:04 |  1.18it/s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTUy', repetition 1\n",
      "\u001b[0m\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTUz', repetition 1\n",
      "\u001b[0m\n",
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTU0', repetition 1\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 (80.0%) | ‚è≥ 00:05<00:01 |  1.28it/s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTU1', repetition 1\n",
      "\u001b[0m\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 (100.0%) | ‚è≥ 00:06<00:00 |  1.91it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mTraceback (most recent call last):\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/experiments/functions.py\", line 305, in async_run_experiment\n",
      "    _output = task(*bound_task_args.args, **bound_task_args.kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_7326/3865991552.py\", line 29, in run_router_step\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 863, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 986, in _request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 506, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type PromptVersion is not JSON serializable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "RuntimeError: task failed for example id 'RGF0YXNldEV4YW1wbGU6MTU2', repetition 1\n",
      "\u001b[0m\n",
      "Retries exhausted after 1 attempts: Object of type PromptVersion is not JSON serializable\n",
      "‚úÖ Task runs completed.\n",
      "üß† Evaluation started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View this experiment: https://app.phoenix.arize.com/datasets/RGF0YXNldDoz/compare?experimentId=RXhwZXJpbWVudDox\n",
      "\n",
      "Experiment Summary (04/18/25 02:38 PM -0400)\n",
      "--------------------------------------------\n",
      "     evaluator   n\n",
      "0  tools_match  10\n",
      "\n",
      "Tasks Summary (04/18/25 02:38 PM -0400)\n",
      "---------------------------------------\n",
      "   n_examples  n_runs  n_errors\n",
      "0          10       0         0\n"
     ]
    }
   ],
   "source": [
    "experiment = run_experiment(\n",
    "    dataset,\n",
    "    run_router_step,\n",
    "    evaluators=[tools_match],\n",
    "    experiment_name=\"Tool Calling Eval\",\n",
    "    experiment_description=\"Evaluating the tool calling step of the agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize your Agent in Development\n",
    "\n",
    "Now you can optimize your agent's routing prompt based on the labeled data you've created so far. To do this in the most automated and flexible way possible, you'll use DSPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running experiment evaluations |          | 0/0 (0.0%) | ‚è≥ 00:01<? | ?it/s\n",
      "running tasks |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 (100.0%) | ‚è≥ 00:08<00:00 |  1.16it/s\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Configure DSPy to use OpenAI\n",
    "dspy_lm = dspy.LM(model=\"gpt-4o-mini\")\n",
    "dspy.settings.configure(lm=dspy_lm)\n",
    "\n",
    "\n",
    "# Define the prompt classification task\n",
    "class RouterPromptSignature(dspy.Signature):\n",
    "    \"\"\"Route a user prompt to the correct tool based on the task requirements.\n",
    "\n",
    "    Available tools:\n",
    "    1. analyze_sales_data: Use for complex analysis of sales data, including trends, patterns, and insights\n",
    "    2. lookup_sales_data: Use for simple data retrieval or filtering of sales records\n",
    "    3. generate_visualization: Use when the user needs visual representation of data\n",
    "    4. no tool called: Use when no tool is needed\n",
    "\n",
    "    The tool selection should be based on:\n",
    "    - The complexity of the analysis needed\n",
    "    - Whether raw data or processed insights are required\n",
    "    - If visualization would help communicate the results\n",
    "    \"\"\"\n",
    "\n",
    "    input_messages = dspy.InputField(\n",
    "        desc=\"The routers input messages. Can include the user's query and any tool calls that have already been made.\"\n",
    "    )\n",
    "    tool_call = dspy.OutputField(\n",
    "        desc=\"A list of tool calls to execute in sequence. Each tool call should include: \"\n",
    "        \"1. tool_name: The name of the tool to use \"\n",
    "    )\n",
    "\n",
    "\n",
    "router = dspy.Predict(RouterPromptSignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    tool_call='{\"tool_name\": \"lookup_sales_data\"}'\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = router(\n",
    "    input_messages=[{\"role\": \"user\", \"content\": \"Which stores had the highest sales volume?\"}]\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Example({'input_messages': [{'role': 'user', 'content': 'Plot daily sales volume over time'}, {'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'assistant', 'tool_calls': [{'id': 'call_1', 'type': 'function', 'function': {'name': 'lookup_sales_data', 'arguments': '{\"prompt\":\"Plot daily sales volume over time\"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_1', 'content': '     Sold_Date  Daily_Sales_Volume\\n0   2021-11-01              1021.0\\n1   2021-11-02              1035.0\\n2   2021-11-03               900.0'}], 'tool_call': 'analyze_sales_data'}) (input_keys={'input_messages'}), Example({'input_messages': [{'role': 'user', 'content': 'What were the top selling products last month?'}, {'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}], 'tool_call': 'lookup_sales_data'}) (input_keys={'input_messages'}), Example({'input_messages': [{'role': 'user', 'content': 'Show me the relationship between promotions and sales'}, {'role': 'system', 'content': 'You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.'}, {'role': 'assistant', 'tool_calls': [{'id': 'call_2', 'type': 'function', 'function': {'name': 'lookup_sales_data', 'arguments': '{\"prompt\":\"Get promotion and sales data\"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_2', 'content': '   On_Promo  Total_Sale_Value\\n0         0          1245678.50\\n1         1           987654.32'}], 'tool_call': 'analyze_sales_data'}) (input_keys={'input_messages'})]\n"
     ]
    }
   ],
   "source": [
    "trainset = []\n",
    "\n",
    "for input_messages, next_tool_call in dataframe.values:\n",
    "    trainset.append(\n",
    "        dspy.Example(input_messages=input_messages, tool_call=next_tool_call).with_inputs(\n",
    "            \"input_messages\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(trainset[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:06<00:02,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimize via BootstrapFinetune.\n",
    "optimizer = dspy.BootstrapFewShot(metric=(lambda x, y, trace=None: x.tool_call == y.tool_call))\n",
    "optimized = optimizer.compile(router, trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    tool_call='lookup_sales_data'\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized(\n",
    "    input_messages=[{\"role\": \"user\", \"content\": \"Which stores had the highest sales volume?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route a user prompt to the correct tool based on the task requirements.\n",
      "\n",
      "Available tools:\n",
      "1. analyze_sales_data: Use for complex analysis of sales data, including trends, patterns, and insights\n",
      "2. lookup_sales_data: Use for simple data retrieval or filtering of sales records\n",
      "3. generate_visualization: Use when the user needs visual representation of data\n",
      "4. no tool called: Use when no tool is needed\n",
      "\n",
      "The tool selection should be based on:\n",
      "- The complexity of the analysis needed\n",
      "- Whether raw data or processed insights are required\n",
      "- If visualization would help communicate the results\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt from the optimized router\n",
    "new_prompt = optimized.signature.instructions\n",
    "print(new_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (8.24.0) and client (8.26.2) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = CompletionCreateParamsBase(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=tools,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": new_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"{user_query}\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# This will update the existing prompt in Phoenix\n",
    "prompt_name = \"self-improving-agent-router\"\n",
    "prompt = px.Client().prompts.create(\n",
    "    name=prompt_name,\n",
    "    prompt_description=\"Router prompt for the self-improving agent\",\n",
    "    version=PromptVersion.from_openai(params),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tag for a prompt version\n",
    "px.Client().prompts.tags.create(\n",
    "    prompt_version_id=prompt.id, name=\"production\", description=\"Ready for production environment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your Agent in Production\n",
    "\n",
    "Now \n",
    "\n",
    "It follows a standard pattern:\n",
    "1. Export traces from Phoenix\n",
    "2. Prepare those exported traces in a dataframe with the correct columns\n",
    "3. Use `llm_classify` to run a standard template across each row of that dataframe and produce an eval label\n",
    "4. Upload the results back into Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_calls():\n",
    "    query = (\n",
    "        SpanQuery()\n",
    "        .where(\n",
    "            \"span_kind == 'LLM'\",\n",
    "        )\n",
    "        .select(question=\"input.value\", output_messages=\"llm.output_messages\")\n",
    "    )\n",
    "\n",
    "    # The Phoenix Client can take this query and return the dataframe.\n",
    "    tool_calls_df = px.Client().query_spans(query, project_name=project_name, timeout=None)\n",
    "    tool_calls_df.dropna(subset=[\"output_messages\"], inplace=True)\n",
    "    print(\"tool_calls_df\", tool_calls_df)\n",
    "\n",
    "    def get_tool_call(outputs):\n",
    "        print(\"get_tool_call\", outputs)\n",
    "        try:\n",
    "            if outputs[0].get(\"message\").get(\"tool_calls\"):\n",
    "                return (\n",
    "                    outputs[0]\n",
    "                    .get(\"message\")\n",
    "                    .get(\"tool_calls\")[0]\n",
    "                    .get(\"tool_call\")\n",
    "                    .get(\"function\")\n",
    "                    .get(\"name\")\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting tool call: {e}\")\n",
    "        finally:\n",
    "            return \"No tool used\"\n",
    "\n",
    "    tool_calls_df[\"tool_call\"] = tool_calls_df[\"output_messages\"].apply(get_tool_call)\n",
    "    tool_definitions_list = [tools] * len(tool_calls_df)\n",
    "    tool_calls_df[\"tool_definitions\"] = tool_definitions_list\n",
    "    return tool_calls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tool_calls(dataframe):\n",
    "    tool_call_eval = llm_classify(\n",
    "        data=dataframe,\n",
    "        template=TOOL_CALLING_PROMPT_TEMPLATE,\n",
    "        rails=[\"correct\", \"incorrect\"],\n",
    "        model=eval_model,\n",
    "        provide_explanation=True,\n",
    "    )\n",
    "\n",
    "    tool_call_eval[\"score\"] = tool_call_eval.apply(\n",
    "        lambda x: 1 if x[\"label\"] == \"correct\" else 0, axis=1\n",
    "    )\n",
    "\n",
    "    return tool_call_eval, dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_and_log_tool_calls():\n",
    "    tool_calls_df = get_tool_calls()\n",
    "    tool_call_eval, dataframe = eval_tool_calls(tool_calls_df)\n",
    "    px.Client().log_evaluations(\n",
    "        SpanEvaluations(eval_name=\"Tool Calling Eval\", dataframe=tool_call_eval),\n",
    "    )\n",
    "\n",
    "    # Merge the evaluation results with the original dataframe on context.span_id\n",
    "    merged_df = pd.merge(tool_call_eval, dataframe, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "    # Return both the evaluation results and the merged dataframe\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (8.24.0) and client (8.26.2) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_calls_df Empty DataFrame\n",
      "Columns: [question, output_messages]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |          | 0/0 (0.0%) | ‚è≥ 00:00<? | ?it/s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tool_call_eval = \u001b[43meval_and_log_tool_calls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36meval_and_log_tool_calls\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_and_log_tool_calls\u001b[39m():\n\u001b[32m      2\u001b[39m     tool_calls_df = get_tool_calls()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     tool_call_eval, dataframe = \u001b[43meval_tool_calls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_calls_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     px.Client().log_evaluations(\n\u001b[32m      5\u001b[39m         SpanEvaluations(eval_name=\u001b[33m\"\u001b[39m\u001b[33mTool Calling Eval\u001b[39m\u001b[33m\"\u001b[39m, dataframe=tool_call_eval),\n\u001b[32m      6\u001b[39m     )\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Merge the evaluation results with the original dataframe on context.span_id\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36meval_tool_calls\u001b[39m\u001b[34m(dataframe)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_tool_calls\u001b[39m(dataframe):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     tool_call_eval = \u001b[43mllm_classify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOOL_CALLING_PROMPT_TEMPLATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrails\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcorrect\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mincorrect\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprovide_explanation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     tool_call_eval[\u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m] = tool_call_eval.apply(\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mcorrect\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m, axis=\u001b[32m1\u001b[39m\n\u001b[32m     12\u001b[39m     )\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tool_call_eval, dataframe\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/evals/classify.py:90\u001b[39m, in \u001b[36mdeprecate_dataframe_arg.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m bound_args = signature.bind_partial(*args, **kwargs)\n\u001b[32m     89\u001b[39m bound_args.apply_defaults()\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/evals/classify.py:337\u001b[39m, in \u001b[36mllm_classify\u001b[39m\u001b[34m(data, model, template, rails, data_processor, system_instruction, verbose, use_function_calling_if_available, provide_explanation, include_prompt, include_response, include_exceptions, max_retries, exit_on_error, run_sync, concurrency, progress_bar_format)\u001b[39m\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m input type.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    336\u001b[39m results, execution_details = executor.run(list_of_inputs)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m labels, explanations, responses, prompts = \u001b[38;5;28mzip\u001b[39m(*results)\n\u001b[32m    338\u001b[39m all_exceptions = [details.exceptions \u001b[38;5;28;01mfor\u001b[39;00m details \u001b[38;5;129;01min\u001b[39;00m execution_details]\n\u001b[32m    339\u001b[39m execution_statuses = [details.status \u001b[38;5;28;01mfor\u001b[39;00m details \u001b[38;5;129;01min\u001b[39;00m execution_details]\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 4, got 0)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[32m/home/sebas/Forks/phoenix/.venv/lib/python3.12/site-packages/phoenix/evals/classify.py\u001b[39m(\u001b[92m337\u001b[39m)\u001b[36mllm_classify\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m    335\u001b[39m \n",
      "\u001b[32m    336\u001b[39m     results, execution_details = executor.run(list_of_inputs)\n",
      "\u001b[32m--> 337\u001b[39m     labels, explanations, responses, prompts = zip(*results)\n",
      "\u001b[32m    338\u001b[39m     all_exceptions = [details.exceptions \u001b[38;5;28;01mfor\u001b[39;00m details \u001b[38;5;28;01min\u001b[39;00m execution_details]\n",
      "\u001b[32m    339\u001b[39m     execution_statuses = [details.status \u001b[38;5;28;01mfor\u001b[39;00m details \u001b[38;5;28;01min\u001b[39;00m execution_details]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_classify |          | 0/0 (0.0%) | ‚è≥ 23:04<? | ?it/s\n"
     ]
    }
   ],
   "source": [
    "tool_call_eval = eval_and_log_tool_calls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see eval labels in Phoenix.\n",
    "\n",
    "# ![Function Calling Evals](https://storage.googleapis.com/arize-phoenix-assets/assets/images/function-calling-evals.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Automated Loop\n",
    "\n",
    "Now you can combine each of these pieces into a single loop in production. That loop will:\n",
    "1. Evaluate the production data at scale using LLM as a Judge\n",
    "2. Extra the correct application runs, and create a new trainset saved in Phoenix\n",
    "3. Pass that trainset into DSPy to generate a newly optimized prompt\n",
    "4. Run an experiment to benchmark the new prompt on previous dev data\n",
    "5. Ask the user whether to apply the new prompt and save it as the production prompt in Phoenix. This step could be automated instead to check against previous experiment benchmarks and auto-apply if this new variant exceeds them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainset(tool_call_eval):\n",
    "    trainset = []\n",
    "    for _, row in tool_call_eval.iterrows():\n",
    "        if row[\"label\"] == \"correct\":\n",
    "            trainset.append(\n",
    "                dspy.Example(\n",
    "                    input_messages=row[\"question\"], tool_call=row[\"tool_call\"]\n",
    "                ).with_inputs(\"input_messages\")\n",
    "            )\n",
    "    return trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trainset(trainset):\n",
    "    trainset_df = pd.DataFrame(trainset)\n",
    "    px.Client().upload_dataset(\n",
    "        dataframe=trainset_df,\n",
    "        dataset_name=\"self-improving-agent-trainset-{}\".format(uuid.uuid4()),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_router(trainset):\n",
    "    optimizer = dspy.BootstrapFewShot(metric=(lambda x, y, trace=None: x.tool_call == y.tool_call))\n",
    "    optimized = optimizer.compile(router, trainset=trainset)\n",
    "    new_prompt = optimized.signature.instructions\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    experiment = run_experiment(\n",
    "        dataset,\n",
    "        run_router_step,\n",
    "        evaluators=[tools_match],\n",
    "        experiment_name=\"Tool Calling Eval\",\n",
    "        experiment_description=\"Evaluating the tool calling step of the agent\",\n",
    "    )\n",
    "    return experiment.eval_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompt(prompt):\n",
    "    params = CompletionCreateParamsBase(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        tools=tools,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": new_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"{user_query}\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # This will update the existing prompt in Phoenix\n",
    "    prompt_name = \"self-improving-agent-router\"\n",
    "    prompt = px.Client().prompts.create(\n",
    "        name=prompt_name,\n",
    "        prompt_description=\"Router prompt for the self-improving agent\",\n",
    "        version=PromptVersion.from_openai(params),\n",
    "    )\n",
    "\n",
    "    px.Client().prompts.tags.create(\n",
    "        prompt_version_id=prompt.id,\n",
    "        name=\"production\",\n",
    "        description=\"Ready for production environment\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_call_eval = eval_and_log_tool_calls()\n",
    "\n",
    "\n",
    "def automated_loop():\n",
    "    tool_call_eval = eval_and_log_tool_calls()\n",
    "    trainset = create_trainset(tool_call_eval)\n",
    "    save_trainset(trainset)\n",
    "    new_prompt = optimize_router(trainset)\n",
    "    experiment_results = run_experiment()\n",
    "    print(experiment_results.eval_summaries())\n",
    "    # Ask user if they want to apply the new prompt\n",
    "    apply_prompt = input(\"Do you want to apply the new prompt? (yes/no): \")\n",
    "\n",
    "    if apply_prompt.lower() not in [\"yes\", \"y\"]:\n",
    "        print(\"Prompt update cancelled.\")\n",
    "        return\n",
    "\n",
    "    print(\"Applying new prompt...\")\n",
    "    save_prompt(new_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
